# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10youdN1nGZqySbbtHRGfBSM6G1Zrxp1j
"""

from google.colab import drive
import os
import json
from requests import post,get
import base64
import requests
import pandas as pd
import time

client_id="baddc1e7acdf4b6ea2e811e21af0c5ef"
client_secret="04f0e112ac05494ead1275c174625571"

def get_token():
    auth_string = f"{client_id}:{client_secret}"
    auth_bytes = auth_string.encode("utf-8")
    auth_base64 = str(base64.b64encode(auth_bytes), "utf-8")

    url = "https://accounts.spotify.com/api/token"
    headers = {
        "Authorization": "Basic " + auth_base64,
        "Content-Type": "application/x-www-form-urlencoded"
    }
    data = {"grant_type": "client_credentials"}

    result = post(url, headers=headers, data=data)
    json_result = json.loads(result.content)
    token = json_result["access_token"]
    return token

# Get token and print
token = get_token()
#new cell
def get_auth_header(token):
    return {"Authorization": "Bearer " + token}

artist_names = [
    "Jungkook", "Selena Gomez", "Justin Bieber", "The Weeknd", "V", "J-hope",
    "Eminem", "Taylor Swift", "Drake", "BTS", "Britney Spears", "Beyonce",
    "Bruno Mars", "Nicki Minaj", "Billie Eilish", "Rihanna", "Lady Gaga"
]

def get_featured_playlists(token, country="US", limit=10):
    url = "https://api.spotify.com/v1/browse/featured-playlists"
    headers = get_auth_header(token)
    params = {"country": country, "limit": limit}

    try:
        response = get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        playlists = data.get('playlists', {}).get('items', [])
        return pd.json_normalize(playlists)
    except Exception as e:
        print(f"‚ùå Error fetching featured playlists: {e}")
        return pd.DataFrame()

def get_playlist_tracks(token, playlist_id):
    headers = get_auth_header(token)
    url = f"https://api.spotify.com/v1/playlists/{playlist_id}/tracks"
    tracks = []
    params = {"limit": 100}

    while url:
        try:
            response = get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            tracks.extend(data.get("items", []))
            url = data.get("next")
            params = None  # Only needed for first request
        except Exception as e:
            print(f"‚ùå Error fetching tracks from playlist {playlist_id}: {e}")
            break

    return pd.json_normalize(tracks)

def search_artist_by_name(token, artist_name):
    url = "https://api.spotify.com/v1/search"
    headers = get_auth_header(token)
    params = {"q": artist_name, "type": "artist", "limit": 1}

    try:
        response = get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        items = data.get("artists", {}).get("items", [])
        if items:
            return items[0]
        else:
            print(f"‚ö†Ô∏è No artist found for: {artist_name}")
            return None
    except Exception as e:
        print(f"‚ùå Error searching for artist '{artist_name}': {e}")
        return None

def get_top_tracks(token, artist_id, market="US"):
    url = f"https://api.spotify.com/v1/artists/{artist_id}/top-tracks"
    headers = get_auth_header(token)
    params = {"market": market}

    try:
        response = get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        return pd.json_normalize(data.get("tracks", []))
    except Exception as e:
        print(f"‚ùå Error fetching top tracks for artist {artist_id}: {e}")
        return pd.DataFrame()

artist_names = [
    "Jungkook", "Selena Gomez", "Justin Bieber", "The Weeknd", "V", "J-hope",
    "Eminem", "Taylor Swift", "Drake", "BTS", "Britney Spears", "Beyonce",
    "Bruno Mars", "Nicki Minaj", "Billie Eilish", "Rihanna", "Lady Gaga"
]

artist_data = []
top_tracks_data = []

for name in artist_names:
    artist = search_artist_by_name(token, name)
    if artist is None:
        continue

    artist_id = artist['id']
    artist_data.append({
        "artist_id": artist_id,
        "name": artist.get("name"),
        "followers": artist.get("followers", {}).get("total"),
        "popularity": artist.get("popularity"),
        "genres": ", ".join(artist.get("genres", [])),
        "spotify_url": artist.get("external_urls", {}).get("spotify"),
    })

    # Get their top tracks
    top_tracks_df = get_top_tracks(token, artist_id)
    if not top_tracks_df.empty:
        top_tracks_df["artist_id"] = artist_id
        top_tracks_df["artist_name"] = artist.get("name")
        top_tracks_data.append(top_tracks_df)

def safe_get(url, headers=None, params=None, max_retries=5):
    for attempt in range(max_retries):
        response = get(url, headers=headers, params=params)

        if response.status_code == 429:
            retry_after = int(response.headers.get("Retry-After", 5))
            print(f"‚è≥ Rate limit hit. Sleeping for {retry_after} seconds...")
            time.sleep(retry_after + 1)
        elif response.status_code >= 400:
            print(f"‚ùå Error {response.status_code}: {response.text}")
            response.raise_for_status()
        else:
            return response

    raise Exception(f"‚ùå Failed after {max_retries} retries: {url}")

def get_artist_albums(token, artist_id):
    headers = get_auth_header(token)
    albums = []
    url = f"https://api.spotify.com/v1/artists/{artist_id}/albums"
    params = {
        "include_groups": "album,single,compilation,appears_on",  # <-- updated here
        "limit": 50
    }

    while url:
        response = safe_get(url, headers=headers, params=params)
        data = response.json()
        albums.extend(data['items'])
        url = data.get('next')
        params = None

    albums_df = pd.json_normalize(albums)
    albums_df.drop_duplicates(subset="id", inplace=True)
    albums_df["artist_id"] = artist_id
    return albums_df

def get_album_tracks(token, album_id):
    headers = get_auth_header(token)
    tracks = []
    url = f"https://api.spotify.com/v1/albums/{album_id}/tracks"
    params = {"limit": 50}

    try:
        while url:
            response = safe_get(url, headers=headers, params=params)
            data = response.json()
            tracks.extend(data['items'])
            url = data.get('next')
            params = None  # Only needed for the first request

        df = pd.json_normalize(tracks)
        df["album_id"] = album_id
        return df

    except Exception as e:
        print(f"‚ö†Ô∏è Skipping album {album_id} due to error: {e}")
        return pd.DataFrame()

import os
import time
import pandas as pd

for artist in artist_data:
    artist_id = artist['artist_id']
    artist_name = artist['name']
    print(f"üéß Fetching albums for: {artist_name}")

    albums_df = get_artist_albums(token, artist_id)
    if not albums_df.empty:
        albums_df["artist_name"] = artist_name
        all_albums.append(albums_df)

# Combine all albums into a single DataFrame
all_albums_df = pd.concat(all_albums, ignore_index=True)
all_albums_df.drop_duplicates(subset='id', inplace=True)
all_albums_df.to_csv("all_albums.csv", index=False)
print(f"‚úÖ Albums collected: {len(all_albums_df)}")

    # Resume from saved progress if available
    if os.path.exists(output_file):
        try:
            existing_df = pd.read_csv(output_file)
            if 'album_id' in existing_df.columns:
                processed_albums = set(existing_df['album_id'].dropna().unique())
            all_tracks.append(existing_df)
            print(f"‚úÖ Resuming from previous progress. Loaded {len(existing_df)} tracks.")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to read existing file. Starting fresh. Reason: {e}")

    for i, album_id in enumerate(album_ids):
        if max_albums and i >= max_albums:
            print(f"‚úÖ Reached max_albums={max_albums}. Stopping.")
            break
        if album_id in processed_albums:
            continue
        try:
            tracks_df = get_album_tracks(token, album_id)
            if not tracks_df.empty:
                all_tracks.append(tracks_df)

            if i % save_every == 0 and i > 0:
                partial_df = pd.concat(all_tracks, ignore_index=True)
                partial_df.to_csv(output_file, index=False)
                print(f"‚úÖ Saved {len(partial_df)} tracks after processing {i} albums.")
                time.sleep(1)

        except KeyboardInterrupt:
            print(f"\n‚èπÔ∏è Interrupted at album {i} ({album_id}). Saving progress...")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è Error with album {album_id}: {e}")
            time.sleep(2)

    final_df = pd.concat(all_tracks, ignore_index=True)
    final_df.to_csv(output_file, index=False)
    print(f"\n‚úÖ Final saved track count: {len(final_df)}")
    return final_df

print("Albums collected:", len(all_albums_df))
print("Tracks collected:", len(all_tracks_df))

# Create cleaned_tracks_df from all_tracks_df with only available columns
cleaned_tracks_df = all_tracks_df[[
    'id', 'name', 'duration_ms', 'explicit',
    'preview_url', 'album_id'
]].copy()

# Rename columns for consistency
cleaned_tracks_df.columns = [
    'track_id', 'track_name', 'duration_ms', 'explicit',
    'preview_url', 'album_id'
]

# Fill missing preview_url with 'N/A'
cleaned_tracks_df['preview_url'] = cleaned_tracks_df['preview_url'].fillna('N/A')

# Optional: Add album name/release date if available in `all_albums_df`
cleaned_tracks_df = cleaned_tracks_df.merge(
    all_albums_df[['id', 'name', 'release_date']],
    how='left',
    left_on='album_id',
    right_on='id'
)

# Drop duplicate 'id' column and rename merged columns
cleaned_tracks_df = cleaned_tracks_df.drop(columns=['id'])
cleaned_tracks_df = cleaned_tracks_df.rename(columns={
    'name': 'album_name',
    'release_date': 'release_date'
})

# Convert release_date to datetime
cleaned_tracks_df['release_date'] = pd.to_datetime(cleaned_tracks_df['release_date'], errors='coerce')

albums_data = all_albums_df[[
    'id', 'name', 'release_date', 'total_tracks'
]].copy()

albums_data.columns = ['album_id', 'album_name', 'release_date', 'total_tracks']
albums_data['release_date'] = pd.to_datetime(albums_data['release_date'], errors='coerce')
albums_data = albums_data.drop_duplicates(subset='album_id')

track_artist_pairs = []

for _, row in all_tracks_df.iterrows():
    track_id = row['id']
    if isinstance(row['artists'], list):
        for artist in row['artists']:
            track_artist_pairs.append({
                'track_id': track_id,
                'artist_id': artist.get('id'),
                'artist_name': artist.get('name')
            })

track_artists_expanded_df = pd.DataFrame(track_artist_pairs)

# Artists table
artists_df = track_artists_expanded_df[['artist_id', 'artist_name']].drop_duplicates()

# Track-Artist mapping table
track_artists_df = track_artists_expanded_df[['track_id', 'artist_id']].drop_duplicates()

# Tracks
cleaned_tracks_df = cleaned_tracks_df.astype({
    'track_id': 'string',
    'track_name': 'string',
    'duration_ms': 'int64',
    'explicit': 'bool',
    'preview_url': 'string',
    'album_id': 'string',
    'album_name': 'string',
    'release_date': 'datetime64[ns]'
})

# Albums
albums_data = albums_data.astype({
    'album_id': 'string',
    'album_name': 'string',
    'release_date': 'datetime64[ns]',
    'total_tracks': 'int32'
})

# Artists
artists_df = artists_df.astype({
    'artist_id': 'string',
    'artist_name': 'string'
})

# Track-Artist mapping
track_artists_df = track_artists_df.astype({
    'track_id': 'string',
    'artist_id': 'string'
})

print("üìä Full Dataset Summary (ALL albums/tracks):")
print(f"Albums collected: {len(albums_data):,}")
print(f"Tracks collected: {len(cleaned_tracks_df):,}")
print(f"Unique albums: {albums_data['album_id'].nunique():,}")
print(f"Unique tracks: {cleaned_tracks_df['track_id'].nunique():,}")
print(f"Artists in this collection: {artists_df['artist_id'].nunique():,}")

import os
os.makedirs("spotify_cleaned_data", exist_ok=True)

# Export
cleaned_tracks_df.to_csv("spotify_cleaned_data/tracks.csv", index=False)
albums_data.to_csv("spotify_cleaned_data/albums.csv", index=False)
artists_df.to_csv("spotify_cleaned_data/artists.csv", index=False)
track_artists_df.to_csv("spotify_cleaned_data/track_artists.csv", index=False)

for file_name in os.listdir("spotify_cleaned_data"):
from google.colab import files

import requests
import pandas as pd
import time
from google.colab import files
import io

